services:
  # -----------------
  # Apache Kafka (KRaft Mode) - Kafka 4.0
  # -----------------
  kafka:
    image: apache/kafka:4.0.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9093:9093"
    environment:
      - KAFKA_NODE_ID=${KAFKA_NODE_ID}
      - KAFKA_PROCESS_ROLES=${KAFKA_PROCESS_ROLES}
      - KAFKA_CONTROLLER_QUORUM_VOTERS=${KAFKA_CONTROLLER_QUORUM_VOTERS}
      - KAFKA_LISTENERS=${KAFKA_LISTENERS}
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=${KAFKA_LISTENER_SECURITY_PROTOCOL_MAP}
      - KAFKA_ADVERTISED_LISTENERS=${KAFKA_ADVERTISED_LISTENERS}
      - KAFKA_INTER_BROKER_LISTENER_NAME=${KAFKA_INTER_BROKER_LISTENER_NAME}
      - KAFKA_CONTROLLER_LISTENER_NAMES=${KAFKA_CONTROLLER_LISTENER_NAMES}
      - KAFKA_LOG_DIRS=${KAFKA_LOG_DIRS}
    volumes:
      - kafka-data:/var/lib/kafka/data
    restart: unless-stopped

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:29092
    depends_on:
      - kafka
    restart: unless-stopped

  # -----------------
  # RabbitMQ (for Celery)
  # -----------------
  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      - RABBITMQ_DEFAULT_USER=${RABBITMQ_DEFAULT_USER}
      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_DEFAULT_PASS}
    restart: unless-stopped

  # -----------------
  # Postgres (Airflow DB)
  # -----------------
  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    restart: unless-stopped

  # -----------------
  # Airflow Webserver
  # -----------------
  airflow:
    image: apache/airflow:2.10.5
    container_name: airflow
    depends_on:
      - postgres
      - rabbitmq
    ports:
      - "8888:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=${AIRFLOW__CORE__EXECUTOR}
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=${AIRFLOW__CORE__SQL_ALCHEMY_CONN}
      - AIRFLOW__CELERY__BROKER_URL=${AIRFLOW__CELERY__BROKER_URL}
      - AIRFLOW__CELERY__RESULT_BACKEND=${AIRFLOW__CELERY__RESULT_BACKEND}
      - AIRFLOW__WEBSERVER__DEFAULT_USER_USERNAME=${AIRFLOW__WEBSERVER__DEFAULT_USER_USERNAME}
      - AIRFLOW__WEBSERVER__DEFAULT_USER_PASSWORD=${AIRFLOW__WEBSERVER__DEFAULT_USER_PASSWORD}
    volumes:
      - airflow-data:/opt/airflow
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: >
      bash -c "
      airflow db upgrade &&
      airflow users create --username ${AIRFLOW__WEBSERVER__DEFAULT_USER_USERNAME} --password ${AIRFLOW__WEBSERVER__DEFAULT_USER_PASSWORD} --firstname Admin --lastname User --role Admin --email admin@example.com &&
      airflow webserver
      "
    restart: unless-stopped

  # -----------------
  # Airflow Scheduler
  # -----------------
  airflow-scheduler:
    image: apache/airflow:2.10.5
    container_name: airflow-scheduler
    depends_on:
      - airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=${AIRFLOW__CORE__EXECUTOR}
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=${AIRFLOW__CORE__SQL_ALCHEMY_CONN}
      - AIRFLOW__CELERY__BROKER_URL=${AIRFLOW__CELERY__BROKER_URL}
      - AIRFLOW__CELERY__RESULT_BACKEND=${AIRFLOW__CELERY__RESULT_BACKEND}
    volumes:
      - airflow-data:/opt/airflow
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: airflow scheduler
    restart: unless-stopped

  # -----------------
  # Airflow Celery Worker
  # -----------------
  airflow-worker:
    image: apache/airflow:2.10.5
    container_name: airflow-worker
    depends_on:
      - airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=${AIRFLOW__CORE__EXECUTOR}
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=${AIRFLOW__CORE__SQL_ALCHEMY_CONN}
      - AIRFLOW__CELERY__BROKER_URL=${AIRFLOW__CELERY__BROKER_URL}
      - AIRFLOW__CELERY__RESULT_BACKEND=${AIRFLOW__CELERY__RESULT_BACKEND}
    volumes:
      - airflow-data:/opt/airflow
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: airflow celery worker
    restart: unless-stopped

volumes:
  kafka-data:
  airflow-data:
  postgres-data:
